{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_processing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0924R6-622ae"
      },
      "source": [
        "# Image Pre-processing for Laver's Law Revisited\n",
        "\n",
        "This notebook contains functions to remove backgrounds (adapted from https://github.com/aadityavikram/Background-Removal) and resize runway photo images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMpaVA5DrW0e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvdNpPVx3aHd"
      },
      "source": [
        "##Install and Import\n",
        "Note: Many of these are old versions to work with background removal code. Possible scikit-image version conflict with other package. If errors occur install/disable package as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cxghRUVsaW3"
      },
      "source": [
        "!pip3 uninstall Keras\n",
        "!pip3 uninstall scipy\n",
        "!pip3 uninstall numpy\n",
        "!pip3 uninstall tensorflow\n",
        "!pip3 uninstall tensorflow-gpu\n",
        "!pip3 install -I tensorflow-gpu==1.15.0\n",
        "!pip3 install -I Keras==2.0.9\n",
        "!pip3 install Pillow\n",
        "!pip3 install -I scipy==1.1.0\n",
        "!pip3 uninstall h5py\n",
        "!pip3 install -I h5py==2.10.0 \n",
        "!pip3 install numpy\n",
        "!pip3 install scikit-image \n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsQ1QDPPrHG-",
        "outputId": "6c7082a3-a2ac-499d-b789-a62ae2aed37f"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "from scipy.misc import imresize\n",
        "import numpy as np\n",
        "import os\n",
        "from skimage import io, img_as_float, transform\n",
        "import cv2\n",
        "import drive\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": [
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMJsvcYj4HMN"
      },
      "source": [
        "##Perform Background Removal\n",
        "Load the model as linked from https://github.com/aadityavikram/Background-Removal. The majority of the three code blocks following come directly from https://github.com/aadityavikram/Background-Removal/blob/master/person.py."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IppHywP5Qj9O"
      },
      "source": [
        "model = load_model('./drive/MyDrive/main_model.hdf5', compile=False)\n",
        "graph = tf.get_default_graph()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tol06M4AgnN0"
      },
      "source": [
        "def predict(image):\n",
        "    with graph.as_default():\n",
        "        # Make prediction\n",
        "        prediction = model.predict(image[None, :, :, :])\n",
        "    prediction = prediction.reshape((224,224, -1))\n",
        "    return prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XiXryExgsL9"
      },
      "source": [
        "def remove(in_folder, out_folder, filename):\n",
        "    try:\n",
        "      image = Image.open(os.path.join(in_folder, filename))\n",
        "      image1 = imresize(image, (224, 224)) / 255.0\n",
        "\n",
        "      prediction = predict(image1[:, :, 0:3])\n",
        "      prediction = imresize(prediction[:, :, 1], (image.height, image.width))\n",
        "      prediction[prediction>0.5*255] = 255\n",
        "      prediction[prediction<0.5*255] = 0\n",
        "\n",
        "      transparency = np.append(np.array(image)[:, :, 0:3], prediction[: , :, None], axis=-1)\n",
        "      png = Image.fromarray(transparency)\n",
        "      # Create bright yellow background (as opposed to white etc.) to help ensure\n",
        "      # distinction from clothing items\n",
        "      new_image = Image.new(\"RGBA\", png.size, \"YELLOW\")\n",
        "      new_image.paste(png, (0, 0), png)  # Paste the image on the background. \n",
        "      basewidth = 399\n",
        "      wpercent = (basewidth / float(new_image.size[0]))\n",
        "      hsize = int((float(new_image.size[1]) * float(wpercent)))\n",
        "      new_image = new_image.resize((basewidth, hsize), Image.ANTIALIAS)\n",
        "      # Could probably remove the step below of resaving then editing again in another format\n",
        "      # with minor refactoring...\n",
        "      new_image.convert('RGB').save(os.path.join(out_folder, filename), \"JPEG\")  # Save as JPEG\n",
        "      getLargestContour(os.path.join(out_folder, filename))\n",
        "    except:\n",
        "      print(\"error\")\n",
        "      pass\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CSAg2wn21Wx"
      },
      "source": [
        "##Remove Artifacts\n",
        "Some photos don't have clealy removed backgrounds, especially photos with many models visible or busy foregrounds.\n",
        "\n",
        "This code takes the bg-removed image and removes everything but the biggest contour.\n",
        "\n",
        "The getLargestContour code was largely lifted from https://stackoverflow.com/questions/58754961/how-to-remove-the-object-marked-by-the-biggest-contour-from-an-image-and-save-it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYPXGT_eNiYD"
      },
      "source": [
        "def getLargestContour(img):\n",
        "  try:\n",
        "    # Read image, create blank masks, color threshold\n",
        "    image = cv2.imread(img)\n",
        "\n",
        "    # # red color boundaries [B, G, R]\n",
        "    lower = [0, 200, 200]\n",
        "    upper = [20, 255, 255]\n",
        "\n",
        "    # create NumPy arrays from the boundaries\n",
        "    lower = np.array(lower, dtype=\"uint8\")\n",
        "    upper = np.array(upper, dtype=\"uint8\")\n",
        "\n",
        "    # # find the colors within the specified boundaries and apply\n",
        "    # # the mask\n",
        "    mask = 255 - cv2.inRange(image, lower, upper)\n",
        "\n",
        "    ret,thresh = cv2.threshold(mask, 40, 255, 0)\n",
        "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    if len(contours) > 0:\n",
        "      # find the biggest countour (c) by the area\n",
        "      c = max(contours, key = cv2.contourArea)\n",
        "      x,y,w,h = cv2.boundingRect(c)\n",
        "\n",
        "      out = image[y:(y+h), x:(x+w)].copy()\n",
        "      height = out.shape[0]\n",
        "      width = out.shape[1]\n",
        "      ratio = width/height\n",
        "      new_height = 440\n",
        "      new_width = int(new_height * ratio)\n",
        "      # if the largest contour is super big or super small\n",
        "      # we assume the pic is badly formatted and we remove it\n",
        "      if new_width > 200 or new_width < 85:\n",
        "        os.remove(img)\n",
        "      else:\n",
        "        resized = cv2.resize(out,(new_width,new_height))\n",
        "        H, W = 445, 399\n",
        "        new_image = np.zeros((H,W,3), np.uint8)\n",
        "        new_image[:] = [0,255,255]\n",
        "        new_image_as_array = new_image\n",
        "        new_image_as_array[2:resized.shape[0]+2,  int(445/2 - new_width/2): int(445/2 - new_width/2) + resized.shape[1]] = resized\n",
        "        cv2.imwrite(img, new_image_as_array)\n",
        "    # delete any images where there are no contours\n",
        "    else: \n",
        "      print(img)\n",
        "      os.remove(img)\n",
        "  except:\n",
        "    print(\"error\")\n",
        "    print(img)\n",
        "    os.remove(img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpwYtk8dpP9Y"
      },
      "source": [
        "## Check for Humans\n",
        "\n",
        "Some of the output is pretty grim (weirdly scaled or random body parts). Here we look for faces in the top 100 pixels of the image and check if they are the right scale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ksR2Zp0zYdc"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load the cascade\n",
        "face_cascade = cv2.CascadeClassifier('./drive/My Drive/haarcascade_frontalface_default.xml')\n",
        "body_cascade = cv2.CascadeClassifier('./drive/My Drive/haarcascade_upperbody.xml')\n",
        "\n",
        "index = 0\n",
        "remove_count = 0\n",
        "for filename in glob.glob(new_folder_base + \"/batch_*/*.jpg\"):\n",
        "  index = index +1\n",
        "  # sanity check\n",
        "  if (index % 1000 == 0):\n",
        "    print(index)\n",
        "    print(remove_count)\n",
        "  # Read the input image\n",
        "  img = cv2.imread(filename)\n",
        "  # Convert into grayscale\n",
        "  gray = cv2.cvtColor(img[0:100], cv2.COLOR_BGR2GRAY)\n",
        "  # faces has very loose detection criteria and may over-detect faces\n",
        "  faces = face_cascade.detectMultiScale(gray, 1.05, 3, minSize=(20,20), maxSize=(100,100))\n",
        "  # strict faces has stricter parameters and may miss faces\n",
        "  strict_faces = face_cascade.detectMultiScale(gray, 1.05, 6, minSize=(30,30), maxSize=(65,65))\n",
        "  # remove pics with no faces\n",
        "  if len(faces) < 1:\n",
        "    remove_count = remove_count + 1\n",
        "    os.remove(filename)\n",
        "    # cv2_imshow(img)\n",
        "  # if there is a face but it is too big, delete it\n",
        "  elif len(strict_faces) > 0:\n",
        "    min_y = min([f[1] for f in strict_faces])\n",
        "    main_face = [f for f in strict_faces if f[1] == min_y][0]\n",
        "    if (main_face[0] > (200 + main_face[2])) or (main_face[0] < (200 - main_face[2]/2)):\n",
        "      os.remove(filename)\n",
        "      remove_count = remove_count + 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}