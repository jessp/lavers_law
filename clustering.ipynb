{
   "nbformat":4,
   "nbformat_minor":0,
   "metadata":{
      "colab":{
         "name":"clustering.ipynb",
         "provenance":[
            
         ],
         "collapsed_sections":[
            
         ],
         "machine_shape":"hm",
         "authorship_tag":"ABX9TyOiCauUR6ESTCAX5vNF5iHj"
      },
      "kernelspec":{
         "display_name":"Python 3",
         "name":"python3"
      }
   },
   "cells":[
      {
         "cell_type":"markdown",
         "metadata":{
            "id":"0eSbYKCS02dk"
         },
         "source":[
            "#Clustering\n",
            "\n",
            "This notebook contains functions to support clustering runway photos iteratively using elcorto's imagecluster library."
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            "id":"terYZb7NuXfA"
         },
         "source":[
            "##Set-up, Install, Import"
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"VHpP1pE9P0g3"
         },
         "source":[
            "from google.colab import drive\n",
            "drive.mount(\"/content/drive\", force_remount=True)"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"jN9vqx2vRW-J"
         },
         "source":[
            "def doMemoryHack():\n",
            "  a = []\n",
            "  while(1):\n",
            "      a.append('1')"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"yjQ0vwmJX9Ai"
         },
         "source":[
            "#get 25GB in Colab since I need it\n",
            "# doMemoryHack()"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"-fIHd51cR-Kp"
         },
         "source":[
            "def runInstalls():\n",
            "  #! git clone https://github.com/elcorto/imagecluster \"./drive/My Drive/project_files/imagecluster\"\n",
            "  ! pip3 uninstall tensorflow-gpu\n",
            "  ! pip3 uninstall tensorflow\n",
            "  ! pip3 install -e \"./drive/My Drive/project_files/imagecluster\""
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"7j_NTtysXcVN"
         },
         "source":[
            "runInstalls()"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"Wgm65NHZe_zl"
         },
         "source":[
            "base_url = \"/content/drive/My Drive/project_files/dataset/test_images_out\""
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"gxsMqFq9R6Fe"
         },
         "source":[
            "import os\n",
            "import sys\n",
            "from pathlib import Path\n",
            "from PIL import Image \n",
            "import shutil\n",
            "import glob\n",
            "sys.path.append(base_url)\n",
            "from imagecluster import calc, io as icio, postproc\n",
            "import pickle\n",
            "import itertools\n",
            "import math\n",
            "import json"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            "id":"zFb4Qwthu7r8"
         },
         "source":[
            "## Calculate Fingerprints from Images\n",
            "\n",
            "Use elcorto's imagecluster library to calculate fingerprints from all images."
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"4oqIFoR7eycg"
         },
         "source":[
            "def calc_fingerprints(in_folder):\n",
            "  for folder in sorted(os.listdir(in_folder)):\n",
            "    if os.path.exists(os.path.join(in_folder, folder, \"imagecluster\", \"fingerprints.pk\")):\n",
            "      os.remove(os.path.join(in_folder, folder, \"imagecluster\", \"fingerprints.pk\"))\n",
            "    images = None\n",
            "    fingerprints = None #being paranoid about memory\n",
            "    timestamps = None\n",
            "    images,fingerprints,timestamps = icio.get_image_data(os.path.join(in_folder, folder))\n",
            "    # Remove the images.pk files since they are too big. \n",
            "    # I think it's possible to skip this step with better written code\n",
            "    os.remove(os.path.join(in_folder, folder, \"imagecluster\", \"images.pk\"))"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"2NcfAXGEfk-V"
         },
         "source":[
            "calc_fingerprints(base_url)"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            "id":"DS64bSDHy9V7"
         },
         "source":[
            "##Combine Fingerprints in One File\n",
            "Put all fingerprint data in a single file. Perform PCA to reduce feature complexity. The 200 comes from the approximate number of features (if memory serves) returned if using n_components=0.9 on files individually."
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"grSm3P4gvSn0"
         },
         "source":[
            "def populate_big_dict(in_folder):\n",
            "  big_pickle = dict()\n",
            "  for folder in sorted(os.listdir(in_folder)):\n",
            "    if len(folder.split(\"batch\")) > 1:\n",
            "      new_dict = pickle.load( open( os.path.join(in_folder, folder, \"imagecluster\", \"fingerprints.pk\"), \"rb\" ) )\n",
            "      big_pickle.update( calc.pca(new_dict, n_components=200))\n",
            "      new_dict = None\n",
            "  return big_pickle\n"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"0OfPpTvIxD25"
         },
         "source":[
            "big_dict = dict()\n",
            "try:\n",
            "  big_dict = pickle.load( open( os.path.join(base_url, \"big_dict.pk\"), \"rb\" ) )\n",
            "except:\n",
            "  big_dict = populate_big_dict(base_url)\n",
            "  pickle.dump( big_dict, open( os.path.join(base_url, \"big_dict.pk\"), \"wb\" ) )"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"if9w2t3kyRu3"
         },
         "source":[
            "len(big_dict.keys())"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            "id":"1ZG-Kyo11Jrz"
         },
         "source":[
            "##Cluster the Image Features Iteratively\n",
            "\n",
            "This method is probably quite bad. I wanted to reduce the number of photos in a non-arbitrary way to work with the data within the notebook's memory limit. To this end, I clustered features multiple times, discarding images from very large and very small clusters, until all could be clustered together. Parameters were chosen based on how cohesive the mid-size looked. \n",
            "\n",
            "Clustering was performed using elcorto's imagecluster library (which uses scipy's hierarchical clustering algorithm)."
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"9qx9kymjJrQF"
         },
         "source":[
            "def cluster_for_noise(num_groups, sim_index, dict_object, min_c, min_filter, max_filter):\n",
            "  iter_group = math.ceil(len(dict_object.keys())/num_groups)\n",
            "  noise = []\n",
            "  idx = 0\n",
            "  while idx < len(dict_object.keys()):\n",
            "    dict_segment = dict(itertools.islice(dict_object.items(), idx, idx + iter_group))\n",
            "    clusters = calc.cluster(dict_segment, sim=sim_index, alpha=0, min_csize=min_c)\n",
            "    print(idx/iter_group)\n",
            "    for cluster in list(clusters.keys()):\n",
            "      if int(cluster) > max_filter or int(cluster) < min_filter:\n",
            "        noise = noise + list(clusters[cluster])\n",
            "    dict_segment = {}\n",
            "    clusters = {}\n",
            "    idx = idx + iter_group\n",
            "  return noise"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"q_NKjHKr5La7"
         },
         "source":[
            "#first round of clustering annd discarding\n",
            "filtered_dict = {}\n",
            "try:\n",
            "  filtered_dict = pickle.load( open( os.path.join(base_url, \"filtered_dict.pk\"), \"rb\" ) )\n",
            "except:\n",
            "  #the num groups argument is usually chosen to give max ~50,000 images per group\n",
            "  #which is about what the memory can handle given num features\n",
            "  first_noise = cluster_for_noise(6, 0.75, big_dict, 1, 4, 500)\n",
            "  first_noise = [item for sublist in first_noise for item in sublist] #flatten\n",
            "  print(len(first_noise))\n",
            "  filtered_dict = {k: v for k, v in big_dict.items() if k not in first_noise}\n",
            "  print(len(filtered_dict))\n",
            "  pickle.dump( filtered_dict, open( os.path.join(base_url, \"filtered_dict.pk\"), \"wb\" ) )"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"CCz41DAb_scS"
         },
         "source":[
            "#second round of clustering annd discarding\n",
            "double_filtered = {}\n",
            "try:\n",
            "  double_filtered = pickle.load( open( os.path.join(base_url, \"double_filtered_dict.pk\"), \"rb\" ) )\n",
            "except:\n",
            "  second_noise = cluster_for_noise(2, 0.65, filtered_dict, 1, 4, 1000)\n",
            "  second_noise = [item for sublist in second_noise for item in sublist]\n",
            "  double_filtered = {k: v for k, v in filtered_dict.items() if k not in second_noise}\n",
            "  pickle.dump( double_filtered, open( os.path.join(base_url, \"double_filtered_dict.pk\"), \"wb\" ) )"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"u5QUqvkiHc5e"
         },
         "source":[
            "#final clustering\n",
            "cluter_dct = {}\n",
            "try:\n",
            "  with open(os.path.join(base_url, 'cluster_dct.json'), 'r') as f:\n",
            "      cluster_dct = json.load(f)\n",
            "except:\n",
            "  clusters = calc.cluster(double_filtered, sim=0.65, alpha=0, min_csize=10)\n",
            "  idx = 0\n",
            "  for cluster_group in clusters:\n",
            "    for cluster in clusters[cluster_group]:\n",
            "      cluster_dct[idx] = cluster\n",
            "      idx = idx + 1\n",
            "  with open(os.path.join(base_url, 'cluster_dct.json'), 'w') as f:\n",
            "    json.dump(cluster_dct, f)"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"l-VrCghkJeOf"
         },
         "source":[
            "#show 10 pictures each of the remaining clusters that have more\n",
            "#than 14 pics total in each. I picked the groups that looked\n",
            "#most cohesive here\n",
            "import cv2\n",
            "from google.colab.patches import cv2_imshow\n",
            "\n",
            "for c in cluster_dct.keys():\n",
            "  if len(cluster_dct[c]) > 14:\n",
            "    try:\n",
            "      print(c)\n",
            "      print(len(cluster_dct[c]))\n",
            "      row_1 = cv2.hconcat((cv2.imread(cluster_dct[c][0]), \\\n",
            "                          cv2.imread(cluster_dct[c][1]), \\\n",
            "                          cv2.imread(cluster_dct[c][2]), \\\n",
            "                          cv2.imread(cluster_dct[c][3]), \\\n",
            "                          cv2.imread(cluster_dct[c][4])))\n",
            "      row_2 = cv2.hconcat((cv2.imread(cluster_dct[c][5]), \\\n",
            "                          cv2.imread(cluster_dct[c][6]), \\\n",
            "                          cv2.imread(cluster_dct[c][7]), \\\n",
            "                          cv2.imread(cluster_dct[c][8]), \\\n",
            "                          cv2.imread(cluster_dct[c][9])))\n",
            "      concat = cv2.vconcat((row_1, row_2))\n",
            "      scale_percent = 50 # percent of original size\n",
            "      width = int(concat.shape[1] * scale_percent / 100)\n",
            "      height = int(concat.shape[0] * scale_percent / 100)\n",
            "      dim = (width, height)\n",
            "      shrunk = cv2.resize(concat, (dim))\n",
            "      row_1 = None\n",
            "      row_2 = None\n",
            "      concat = None\n",
            "      cv2_imshow(shrunk)\n",
            "    except:\n",
            "      print(\"ERROR\")\n"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            "id":"Xi80d_so3gCj"
         },
         "source":[
            "##Light Analysis\n",
            "Let's just have a little peek at the data"
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"obDx-jgvRqtS"
         },
         "source":[
            "import pandas as pd\n",
            "\n",
            "array_for_pandas = []\n",
            "for cluster in cluster_dct:\n",
            "  for image in cluster_dct[cluster]:\n",
            "    split_name = image.split(\"~\")\n",
            "    year = split_name[0][-4:]\n",
            "    designer = split_name[1]\n",
            "    array_for_pandas.append({\"name\": image, \"year\": year, \"designer\": designer, \"cluster\": cluster})\n",
            "\n",
            "clothes_df = pd.DataFrame(data=array_for_pandas)"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "colab":{
               "base_uri":"https://localhost:8080/",
               "height":204
            },
            "id":"a9m9U_bRT4Qd",
            "executionInfo":{
               "status":"ok",
               "timestamp":1610918394532,
               "user_tz":0,
               "elapsed":864,
               "user":{
                  "displayName":"Jess Peter",
                  "photoUrl":"",
                  "userId":"09264012492012198174"
               }
            },
            "outputId":"e473cb95-962c-4004-d0fa-403ecabbb348"
         },
         "source":[
            "clothes_df.head()"
         ],
         "execution_count":null,
         "outputs":[

         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"qZqR5UL_T8CS"
         },
         "source":[
            "clothes_df.shape"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"I4vmHcdyUCH7"
         },
         "source":[
            "#paranoid removal of images with non-valid years...\n",
            "#there were about 7 in my batch somehow\n",
            "clothes_df = clothes_df[clothes_df.year.apply(lambda x: x.isnumeric())]"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"dWW4JsBsXtxW"
         },
         "source":[
            "clothes_df.shape"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"53dkcjb6X-Wa"
         },
         "source":[
            "#most frequently recurring designers\n",
            "clothes_df.groupby(\"designer\").count().sort_values(\"name\", ascending=False).head(10)"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"VHBfrZGk0QMI"
         },
         "source":[
            "#in case we haven't properly stripped out weird years\n",
            "clothes_df = clothes_df.astype({'year': 'int32'})\n",
            "just_years = clothes_df[clothes_df.year > 1988][clothes_df.year < 2015]"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"vCjHj59yWtnB"
         },
         "source":[
            "#most cohesive (to me) looking clusters\n",
            "good_clusters = [\"310\",\"985\",\"26\",\"55\",\"999\",\"1009\",\"1134\",\"1194\",\"808\",\"840\",\"511\",\"112\",\"350\",\"373\",\"481\",\"483\",\"923\",\"892\",\"531\",\"535\",\"549\",\"43\",\"49\",\"50\",\"74\",\"75\",\"76\",\"130\",\"277\",\"289\",\"295\",\"297\",\"316\",\"405\",\"425\",\"430\",\"435\",\"494\",\"501\",\"787\",\"886\",\"901\",\"943\",\"968\",\"993\",\"1021\",\"1025\", \"394\", \"397\", \"410\"]"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"Ff4tzq_02FYQ"
         },
         "source":[
            "just_good_clusters = just_years[just_years[\"cluster\"].isin(good_clusters)]"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"yeYqUZfAKsa9"
         },
         "source":[
            "#split out the photo id so we're not saving out to folders\n",
            "just_good_clusters[\"file_name\"] = just_good_clusters[\"name\"].str.split(\"~\", n=-1, expand=True)[2]"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"UAM8d4MMNAy0"
         },
         "source":[
            "#export cluster data to a csv\n",
            "just_good_clusters[[\"year\", \"designer\", \"cluster\", \"file_name\"]].to_csv(\"/content/drive/MyDrive/project_files/data.csv\", index=False)"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            "id":"hKsjzERn6klc"
         },
         "source":[
            "##Export Pics\n",
            "Replace yellow background with transparent background. Export 1 version very small, one slightly bigger for timeline graphic\n",
            "\n",
            "Background colour removal once again lifted from https://stackoverflow.com/questions/58754961/how-to-remove-the-object-marked-by-the-biggest-contour-from-an-image-and-save-it"
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"44Z_GU2p-0Xz"
         },
         "source":[
            "import numpy as np\n",
            "import cv2\n",
            "from google.colab.patches import cv2_imshow\n",
            "\n",
            "# yellow color boundaries [B, G, R]\n",
            "lower = [0, 210, 210, 255]\n",
            "upper = [110, 255, 255, 255]\n",
            "\n",
            "# create NumPy arrays from the boundaries\n",
            "lower = np.array(lower, dtype=\"uint8\")\n",
            "upper = np.array(upper, dtype=\"uint8\")\n",
            "index = 0\n",
            "for row in just_good_clusters.iterrows():\n",
            "  name = row[1][0]\n",
            "  cluster = row[1][3]\n",
            "  im_name = name.split(\"/\")[len(name.split(\"/\")) - 1]\n",
            "  yellow_img = cv2.imread(name)\n",
            "  b_channel, g_channel, r_channel = cv2.split(yellow_img)\n",
            "  alpha_channel = np.full_like(yellow_img[...,0], 255)\n",
            "  img_BGRA = cv2.merge((b_channel, g_channel, r_channel, alpha_channel)) \n",
            "  # find the colors within the specified boundaries and apply the mask\n",
            "  mask = cv2.inRange(img_BGRA, lower, upper)\n",
            "  # Change image to red where we found brown\n",
            "  img_BGRA[mask>0]=(255,255,255,0)\n",
            "  im_name_concat = im_name.split(\"~\")[len(im_name.split(\"~\")) - 1]\n",
            "  \n",
            "  scale_percent_sm = 7 # percent of original size\n",
            "  width_sm = int(img_BGRA.shape[1] * scale_percent_sm / 100)\n",
            "  height_sm = int(img_BGRA.shape[0] * scale_percent_sm / 100)\n",
            "  dim_sm = (width_sm, height_sm)\n",
            "  resized_sm = cv2.resize(img_BGRA, dim_sm, interpolation = cv2.INTER_AREA)\n",
            "  cv2.imwrite(os.path.join(\"/content/drive/MyDrive/project_files\", \"out_sm\", im_name_concat[:-3]+\"png\"), resized_sm)\n",
            "\n",
            "  scale_percent_md = 55 # percent of original size\n",
            "  width_md = int(img_BGRA.shape[1] * scale_percent_md / 100)\n",
            "  height_md = int(img_BGRA.shape[0] * scale_percent_md / 100)\n",
            "  dim_md = (width_md, height_md)\n",
            "  resized_md = cv2.resize(img_BGRA, dim_md, interpolation = cv2.INTER_AREA)\n",
            "  cv2.imwrite(os.path.join(\"/content/drive/MyDrive/project_files\", \"out_md\", im_name_concat[:-3]+\"png\"), resized_md)\n"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"markdown",
         "metadata":{
            "id":"K5JL3l4h824M"
         },
         "source":[
            "##Normalize Data\n",
            "Export number of pictures per year so we can see % of images per year to account for years with very few pics"
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"EfUUN2M5OVZc"
         },
         "source":[
            "big_dict_array_for_pandas = []\n",
            "for image in big_dict:\n",
            "  split_name = image.split(\"~\")\n",
            "  year = split_name[0][-4:]\n",
            "  designer = split_name[1]\n",
            "  big_dict_array_for_pandas.append({\"name\": image, \"year\": year})\n",
            "\n",
            "all_clothes_df = pd.DataFrame(data=big_dict_array_for_pandas)"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      },
      {
         "cell_type":"code",
         "metadata":{
            "id":"WuuI-fj2O0Wq"
         },
         "source":[
            "all_clothes_df.groupby(\"year\", as_index = False).count().to_csv(\"/content/drive/MyDrive/project_files/fashion_years.csv\", index=False)"
         ],
         "execution_count":null,
         "outputs":[
            
         ]
      }
   ]
}